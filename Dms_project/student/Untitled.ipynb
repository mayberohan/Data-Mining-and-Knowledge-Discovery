{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ae9476-0a1f-4c4b-916c-8d7893739cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Performance Comparison (5-fold CV) ===\n",
      "            Model    R2 CV  RMSE CV   MAE CV\n",
      "    Random Forest 0.843226 1.267536 0.823688\n",
      "Linear Regression 0.836264 1.296538 0.843733\n",
      "          XGBoost 0.834640 1.296593 0.833690\n",
      "Gradient Boosting 0.831899 1.309955 0.838692\n",
      "    Decision Tree 0.691374 1.773346 1.018187\n"
     ]
    }
   ],
   "source": [
    "# === Student Performance: All Features -> Predict G3 (CV Comparison) ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Try XGBoost if available (optional)\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load data  (Portuguese set)\n",
    "# -----------------------------\n",
    "# If you're using the merged/cleaned file, change the path accordingly.\n",
    "df = pd.read_csv(\"student-por.csv\", sep=\";\")\n",
    "\n",
    "# Target and features\n",
    "target = \"G3\"\n",
    "y = df[target]\n",
    "X = df.drop(columns=[target])\n",
    "\n",
    "# Column types\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Preprocessing\n",
    "#    - OneHot for categoricals\n",
    "#    - Scale numerics (with_mean=False to work with sparse design)\n",
    "# -----------------------------\n",
    "numeric_tf = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler(with_mean=False))\n",
    "])\n",
    "\n",
    "categorical_tf = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_tf, num_cols),\n",
    "        (\"cat\", categorical_tf, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Models to compare\n",
    "# -----------------------------\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    # Full depth Decision Tree (no max_depth)\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(\n",
    "        n_estimators=400, random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "}\n",
    "\n",
    "if HAS_XGB:\n",
    "    models[\"XGBoost\"] = XGBRegressor(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Cross-validation setup\n",
    "# -----------------------------\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Built-in scorers: use the negative versions and flip the sign afterward\n",
    "scoring = {\n",
    "    \"r2\": \"r2\",\n",
    "    \"rmse\": \"neg_root_mean_squared_error\",\n",
    "    \"mae\": \"neg_mean_absolute_error\"\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Run CV for each model\n",
    "# -----------------------------\n",
    "rows = []\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"prep\", preprocess),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    cv_results = cross_validate(\n",
    "        pipe, X, y, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False\n",
    "    )\n",
    "\n",
    "    r2_mean  = np.mean(cv_results[\"test_r2\"])\n",
    "    rmse_mean = -np.mean(cv_results[\"test_rmse\"])  # flip sign back\n",
    "    mae_mean  = -np.mean(cv_results[\"test_mae\"])   # flip sign back\n",
    "\n",
    "    rows.append({\n",
    "        \"Model\": name,\n",
    "        \"R2 CV\": r2_mean,\n",
    "        \"RMSE CV\": rmse_mean,\n",
    "        \"MAE CV\": mae_mean\n",
    "    })\n",
    "\n",
    "results = pd.DataFrame(rows).sort_values(\"R2 CV\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"=== Model Performance Comparison (5-fold CV) ===\")\n",
    "print(results.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56daecd-87c4-4bef-9516-25c25da26e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf75c03f-d204-48e5-8cc6-ee960da45875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
